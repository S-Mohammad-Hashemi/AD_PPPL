{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-Mohammad-Hashemi/AD_PPPL/blob/main/PPPL_Scenario3_CICIDS2017.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "2EPrBkcDyP-q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/S-Mohammad-Hashemi/AD_PPPL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPQDD44l2V2f",
        "outputId": "3f30c397-8d73-45c6-a7a3-e95e492e5d20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AD_PPPL'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 29 (delta 7), reused 6 (delta 1), pack-reused 11\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n",
            "Checking out files: 100% (10/10), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd AD_PPPL/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjlMVZKx2aOI",
        "outputId": "06c11680-d5ac-4f2f-d82a-7293776a816a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AD_PPPL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash ./extract_cicids_dataset.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjAv9JCF2fmw",
        "outputId": "b737c5e1-7f3a-4bbb-837e-29f704cc1c65"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  datasets/CICIDS2017_packet-based/tuesday.zip\n",
            "   creating: datasets/CICIDS2017_packet-based/tuesday/\n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/labels.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00000.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00001.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00002.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00003.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00004.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00005.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00006.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00007.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00008.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00009.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00010.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00011.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00012.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00013.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00014.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00015.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00016.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00017.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00018.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00019.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00020.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00021.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00022.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/tuesday/part_00023.npy  \n",
            "Archive:  datasets/CICIDS2017_packet-based/wednesday.zip\n",
            "   creating: datasets/CICIDS2017_packet-based/wednesday/\n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/labels.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00000.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00001.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00002.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00003.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00004.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00005.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00006.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00007.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00008.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00009.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00010.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00011.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00012.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00013.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00014.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00015.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00016.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00017.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00018.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00019.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00020.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00021.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00022.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00023.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00024.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00025.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00026.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00027.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/wednesday/part_00028.npy  \n",
            "Archive:  datasets/CICIDS2017_packet-based/thursday.zip\n",
            "   creating: datasets/CICIDS2017_packet-based/thursday/\n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/labels.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00000.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00001.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00002.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00003.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00004.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00005.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00006.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00007.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00008.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00009.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00010.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00011.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00012.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00013.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00014.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00015.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00016.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00017.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00018.npy  \n",
            "  inflating: datasets/CICIDS2017_packet-based/thursday/part_00019.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the dataset\n",
        "dataset_path='./datasets/CICIDS2017_packet-based/' \n",
        "\n",
        "datasets = {\n",
        "    'A':'tuesday',\n",
        "    'B':'wednesday',\n",
        "    'C':'thursday'\n",
        "    }\n",
        "\n",
        "#### src_domain and trg_domain can be any of the above domains.\n",
        "s_domain = datasets['A'] #source domain\n",
        "t_domain = datasets['B'] #target domain"
      ],
      "metadata": {
        "id": "t0pz-qmX3I_2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "pZNN4eBa25uF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import  preproces_dataset, Solver, PacketModel, DataHandler"
      ],
      "metadata": {
        "id": "oqVbWFZ51QsG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading and preprocessing data"
      ],
      "metadata": {
        "id": "vhSePmL83-qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_src,y_src,x_trg,y_trg,train_min,train_max = preproces_dataset(s_domain,t_domain,dataset_path)\n",
        "\n",
        "##### Uncomment the next two lines to make the training procedure faster!\n",
        "# x_trg = x_trg[::2]\n",
        "# y_trg = y_trg[::2]\n",
        "\n",
        "y_src_onehot = np.zeros((len(y_src),2),np.float32)\n",
        "y_src_onehot[range(len(y_src)),y_src.astype(np.int32)] = 1.\n",
        "\n",
        "y_trg_onehot = np.zeros((len(y_trg),2),np.float32)\n",
        "y_trg_onehot[range(len(y_trg)),y_trg.astype(np.int32)] = 1.\n",
        "\n",
        "print('x_src.shape:',x_src.shape,'y_src.shape:',y_src.shape,'x_trg.shape:',x_trg.shape,'y_trg.shape:',y_trg.shape)\n",
        "print('Malicious ratio in the source domain:',np.sum(y_src==1)/len(y_src))\n",
        "print('Malicious ratio in the target domain:',np.sum(y_trg==1)/len(y_trg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1TH3O4w4KsP",
        "outputId": "197d8a8c-fa7d-4ace-d2c8-74fd7ee8d1ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./datasets/CICIDS2017_packet-based/tuesday/part_00000.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00001.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00002.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00003.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00004.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00005.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00006.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00007.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00008.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00009.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00010.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00011.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00012.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00013.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00014.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00015.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00016.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00017.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00018.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00019.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00020.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00021.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00022.npy\n",
            "./datasets/CICIDS2017_packet-based/tuesday/part_00023.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00000.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00001.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00002.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00003.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00004.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00005.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00006.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00007.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00008.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00009.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00010.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00011.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00012.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00013.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00014.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00015.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00016.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00017.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00018.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00019.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00020.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00021.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00022.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00023.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00024.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00025.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00026.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00027.npy\n",
            "./datasets/CICIDS2017_packet-based/wednesday/part_00028.npy\n",
            "x_src.shape: (573544, 580) y_src.shape: (573544,) x_trg.shape: (685241, 580) y_trg.shape: (685241,)\n",
            "Malicious ratio in the source domain: 0.021738523984210452\n",
            "Malicious ratio in the target domain: 0.18153175306206137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a model on the src domain\n"
      ],
      "metadata": {
        "id": "ftk6Vkg74_1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step_eager(x, y, optimizer,net, train_loss):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = net(x, training=True)\n",
        "        mse_loss = tf.reduce_sum((y - y_pred)**2,axis=1)\n",
        "        mse_loss = tf.reduce_mean(mse_loss)\n",
        "    gradients = tape.gradient(mse_loss, net.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
        "    train_loss(mse_loss)\n",
        "    \n"
      ],
      "metadata": {
        "id": "nX583yC95a-H"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_on_src(nb_iters,dhandler,tsolver, train_loss, train_step):\n",
        "    st = time.time()\n",
        "    train_loss.reset_states()\n",
        "    for i in range(nb_iters):\n",
        "        x_batch,y_batch = dhandler.next_batch()\n",
        "\n",
        "        if i%5==0:\n",
        "            tsolver.iters+=1\n",
        "            tsolver.update_lr()\n",
        "\n",
        "        train_step(x_batch,y_batch,tsolver.optimizer,tsolver.net, train_loss)\n",
        "        if i % 50 == 49 or i == nb_iters - 1:\n",
        "            remained_iters = nb_iters - i\n",
        "            passed_time = time.time() - st\n",
        "            ETA = int(passed_time * remained_iters / i)\n",
        "            ETA_min, ETA_sec = ETA // 60, ETA % 60\n",
        "            mean_loss = train_loss.result().numpy()\n",
        "            print ('\\r' + \\\n",
        "                  ' iter: ' + str(i + 1) + '/' + str(nb_iters) + \\\n",
        "                  ' ETA: ' + str(ETA_min) + ':' + \"{0:02d}\".format(ETA_sec) + \\\n",
        "                  ' loss: ' + \"{0:0.4f}\".format(mean_loss),end=\" \")\n",
        "            sys.stdout.flush()\n",
        "    print(' ')\n",
        "\n"
      ],
      "metadata": {
        "id": "0o1fLVa_5axe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_model_on_src():\n",
        "    train_step = tf.function(train_step_eager)\n",
        "    input_size = x_src.shape[1]\n",
        "    net = PacketModel()\n",
        "    net._set_inputs(tf.TensorSpec([None,input_size]))\n",
        "\n",
        "    base_lr = 0.0001\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=base_lr)\n",
        "    grads = []\n",
        "    for v in net.trainable_variables:\n",
        "        grads.append(np.zeros(v.shape))\n",
        "    optimizer.apply_gradients(zip(grads,net.trainable_variables))\n",
        "\n",
        "    tsolver = Solver(optimizer,net,base_lr)\n",
        "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "    nb_epochs = 6\n",
        "    batch_size = 256\n",
        "    total_batch = len(x_src)//batch_size\n",
        "    if len(x_src) % batch_size!=0:\n",
        "        total_batch+=1\n",
        "    RANDOM_SEED = 2022\n",
        "    rng = np.random.RandomState(RANDOM_SEED)\n",
        "\n",
        "\n",
        "    for i in range(nb_epochs):\n",
        "        pos_inds = y_src==1\n",
        "        x_src_pos = x_src[pos_inds]\n",
        "        y_src_pos = y_src_onehot[pos_inds]\n",
        "        x_src_neg = x_src[~pos_inds]\n",
        "        y_src_neg = y_src_onehot[~pos_inds]\n",
        "        p = np.random.permutation(len(x_src_neg))\n",
        "        x_src_neg = x_src_neg[p]\n",
        "        y_src_neg = y_src_neg[p]\n",
        "        pos_len = len(x_src_pos)\n",
        "\n",
        "        src_dhandler = DataHandler(np.concatenate((x_src_pos,x_src_neg[:pos_len]))\n",
        "                                            ,np.concatenate((y_src_pos,y_src_neg[:pos_len])),None,batch_size=256,shuffle=True)\n",
        "\n",
        "        train_model_on_src(total_batch,src_dhandler,tsolver, train_loss, train_step)\n",
        "\n",
        "    return net, tsolver\n",
        "\n"
      ],
      "metadata": {
        "id": "xJYh5NQYv9be"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step_eager(x,net):\n",
        "    return net(x,training=False)\n",
        "\n",
        "test_step = tf.function(test_step_eager)\n",
        "\n",
        "def test(x_ds,y_ds,net,ret=False):\n",
        "    batch_size = 256\n",
        "    all_y_pred = np.zeros_like(y_ds)\n",
        "    all_scores = np.zeros((len(y_ds),2))\n",
        "    for i in range(0,len(x_ds),batch_size):\n",
        "        x_batch = x_ds[i:i+batch_size]\n",
        "        y_batch = y_ds[i:i+batch_size]\n",
        "        y_pred = test_step(x_batch,net)\n",
        "        y_pred = y_pred.numpy()\n",
        "        all_scores[i:i+batch_size] = y_pred\n",
        "        y_pred = y_pred.argmax(axis=1)\n",
        "        all_y_pred[i:i+batch_size] = y_pred\n",
        "    if ret:\n",
        "        return all_y_pred,all_scores\n",
        "    print('accuracy:',np.sum(all_y_pred==y_ds)/len(y_ds))\n",
        "\n",
        "def calc_f1_score(x_ds, y_ds, net):\n",
        "    all_y_pred,_ = test(x_ds,y_ds,net,ret=True)\n",
        "    f1_score = metrics.f1_score(y_true=y_ds,y_pred=all_y_pred)\n",
        "    return f1_score\n"
      ],
      "metadata": {
        "id": "aXpQo2f4w5Db"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1, tsolver1 = train_one_model_on_src()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffnFxKF-vpO0",
        "outputId": "52fbd1a6-814f-4afd-a452-54d1a7c2f010"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 2241/2241 ETA: 0:00 loss: 0.0353  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0153  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0110  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0102  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0085  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0082  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-15T22:52:15.429404Z",
          "start_time": "2021-06-15T22:52:15.405785Z"
        },
        "id": "zDNVcT260-rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3875bceb-b850-44dd-fdf6-c14d01ca25df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score on the trg domain: 0.05157029331462303\n"
          ]
        }
      ],
      "source": [
        "only_src_f1_score = calc_f1_score(x_trg,y_trg, net1)\n",
        "print('F1 score on the trg domain:',only_src_f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bfXYE6z50-r2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfa3a3a-2c8f-496c-8d11-10e87cf3a246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter: 2241/2241 ETA: 0:00 loss: 0.0355  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0147  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0117  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0088  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0077  \n",
            " iter: 2241/2241 ETA: 0:00 loss: 0.0064  \n"
          ]
        }
      ],
      "source": [
        "net2, tsolver2 = train_one_model_on_src()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "only_src_f1_score = calc_f1_score(x_trg,y_trg, net2)\n",
        "print('F1 score on the trg domain:',only_src_f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuAZ240Iygbw",
        "outputId": "03505291-6def-4374-980c-d78bcc2bc45b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score on the trg domain: 0.06554966122170283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPD5p4GK0-r2"
      },
      "source": [
        "# Domain Adaptation with PPPL\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_pseudo_labels(trg_probs_np,trg_cp):\n",
        "    n_classes = 2\n",
        "    pseudo_labels = trg_probs_np.argmax(axis=1)\n",
        "    current_cp = np.zeros(n_classes)\n",
        "    for c in range(n_classes):\n",
        "        current_cp[c] = np.sum(pseudo_labels==c)/len(trg_probs_np)\n",
        "\n",
        "    diff_class_rates =  current_cp - trg_cp\n",
        "    for i in range(len(diff_class_rates)):\n",
        "        if diff_class_rates[i]<=0:\n",
        "            continue\n",
        "        predicted_as_c = pseudo_labels==i\n",
        "        current_class = i\n",
        "        current_diff = diff_class_rates[i]\n",
        "        current_num = np.round(current_diff*len(trg_probs_np)).astype(np.int32)\n",
        "\n",
        "        current_probs = trg_probs_np[pseudo_labels==current_class]\n",
        "        current_probs_sorted = np.sort(current_probs,axis=1)\n",
        "        current_certainty_scores = current_probs_sorted[:,-1] - current_probs_sorted[:,-2]\n",
        "        \n",
        "        current_certainty_scores_sorted_inds = np.argsort(current_certainty_scores)\n",
        "        y_val = np.ones(len(current_certainty_scores))*current_class\n",
        "        for j in range(current_num):\n",
        "            y_val[j]=1-current_class ###change pseudo-label to the opposite class!\n",
        "#             y_val[j]=-1\n",
        "        temp_pl = np.zeros(len(current_certainty_scores))\n",
        "        temp_pl[current_certainty_scores_sorted_inds] = y_val\n",
        "        pseudo_labels[predicted_as_c] = temp_pl\n",
        "    \n",
        "    return pseudo_labels"
      ],
      "metadata": {
        "id": "VyE2wO_tAlYQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step_DA_eager(x, y, w, optimizer,net, train_loss):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = net(x, training=True)\n",
        "        mse_loss = tf.reduce_sum((y - y_pred)**2,axis=1)*w\n",
        "        mse_loss = tf.reduce_mean(mse_loss)\n",
        "    gradients = tape.gradient(mse_loss, net.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
        "    train_loss(mse_loss)\n"
      ],
      "metadata": {
        "id": "bDiL2SrnApfn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_weights(nb_epochs,dhandler,tsolver, train_loss, train_step_DA):\n",
        "    total_batch = dhandler.len // dhandler.batch_size\n",
        "    if dhandler.len % dhandler.batch_size != 0:\n",
        "        total_batch += 1\n",
        "    st = time.time()\n",
        "    for ep in range(nb_epochs):\n",
        "        train_loss.reset_states()\n",
        "        for i in range(total_batch):\n",
        "            x_batch,y_batch_t,w_batch = dhandler.next_batch()\n",
        "            y_batch = np.zeros((dhandler.batch_size,2),dtype=np.float32)\n",
        "            y_batch[range(dhandler.batch_size),y_batch_t] = 1\n",
        "            train_step_DA(x_batch,y_batch,w_batch,tsolver.optimizer,tsolver.net, train_loss)\n",
        "\n",
        "        passed_time = time.time() - st\n",
        "        remained_epochs = nb_epochs - ep\n",
        "        ETA = int(passed_time * remained_epochs)\n",
        "        ETA_min, ETA_sec = ETA // 60, ETA % 60\n",
        "        print ('\\r' + 'epoch: ' + str(ep + 1) + '/' + str(nb_epochs) + \\\n",
        "                      ' ETA: ' + str(ETA_min) + ':' + \"{0:02d}\".format(ETA_sec) + \\\n",
        "                      ' loss: ' + \"{0:0.4f}\".format(train_loss.result().numpy()),end=\" \")\n",
        "        sys.stdout.flush()\n",
        "    print(' ')"
      ],
      "metadata": {
        "id": "g86iGiLLA4t6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DA(tsolver,trg_data,trg_gts,src_data,src_gts,trg_cp, train_loss, train_step_DA ,W = 0.):\n",
        "    begin_time = time.time()\n",
        "    n_classes = 2\n",
        "    my_coef = 0.05\n",
        "    weights_src = np.ones(len(src_gts))\n",
        "    trg_gts_unreal = np.zeros(len(trg_data))\n",
        "\n",
        "\n",
        "    for nnn in range(0,90,2):\n",
        "        print ('^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i:',nnn//2 + 1,\n",
        "               'Elapsed Time(m): {0:0.2f}'.format((time.time()-begin_time)/60))\n",
        "        \n",
        "        #### Get scores and pseudo labels of the target domain\n",
        "        trg_pseudo_labels, trg_scores_np  = test(trg_data,trg_gts_unreal,tsolver.net,ret=True)\n",
        "\n",
        "        if nnn<60:\n",
        "            # Update target class proportions for scenario 3\n",
        "            for i in range(2):\n",
        "                temp = np.sum(trg_pseudo_labels==i)/len(trg_pseudo_labels)\n",
        "                trg_cp[i] = (1-W)*trg_cp[i] + W*temp\n",
        "\n",
        "        trg_pseudo_labels_adjusted = adjust_pseudo_labels(np.copy(trg_scores_np),trg_cp)\n",
        "        if nnn<60:\n",
        "            ### for the first 30 iterations instead of exclusion of samples \n",
        "            ### that their CP is larger than expected CP we change their pseudo-label\n",
        "            ### to the oposite class and keep them into the training set!\n",
        "            trg_pseudo_labels = trg_pseudo_labels_adjusted\n",
        "\n",
        "        ### Calculate the certainty scores for target samples\n",
        "        trg_scores_np_sorted = np.sort(trg_scores_np,axis=1)\n",
        "        certainty_scores = trg_scores_np_sorted[:,-1] - trg_scores_np_sorted[:,-2]\n",
        "        \n",
        "\n",
        "        ### Calculate weight for the target samples\n",
        "        weights_trg = np.zeros(len(certainty_scores))\n",
        "        for c in range(n_classes):\n",
        "            predicted_as_c = trg_pseudo_labels==c\n",
        "            size_c = np.sum(predicted_as_c)\n",
        "            if size_c>1:\n",
        "                left_size = int(np.ceil(((nnn+1)*0.01+0.1)*size_c))\n",
        "                x_val_left = 1+(10/2 - 1)/left_size*(np.arange(left_size))\n",
        "                right_size = size_c - left_size\n",
        "                x_val_right = 10000*(np.arange(1,right_size+1))\n",
        "                x_val = np.concatenate((x_val_left,x_val_right))\n",
        "                y_val = np.power(x_val,-1)\n",
        "                y_val = y_val[::-1]\n",
        "\n",
        "                cs_c = certainty_scores[predicted_as_c]\n",
        "                cs_c_sorted_inds = np.argsort(cs_c)\n",
        "                weights_trg2 = np.zeros(len(cs_c))\n",
        "                weights_trg2[cs_c_sorted_inds] = y_val\n",
        "                weights_trg[predicted_as_c] = weights_trg2\n",
        "                \n",
        "        ### Exclude\n",
        "        coef = (trg_pseudo_labels==trg_pseudo_labels_adjusted)*1\n",
        "        weights_trg*=coef\n",
        "        inclusion_condition = weights_trg>=0.001\n",
        "        trg_samples = trg_data[inclusion_condition]\n",
        "        trg_pseudo_labels = trg_pseudo_labels[inclusion_condition].astype(np.int32)\n",
        "        weights_trg = weights_trg[inclusion_condition]\n",
        "\n",
        "\n",
        "        #### Randomly select some samples from the source domain\n",
        "        p = np.random.permutation(len(src_data))\n",
        "        p = p[:len(trg_data)]\n",
        "        x_temp = src_data[p]\n",
        "        y_temp = src_gts[p]\n",
        "        w_temp = weights_src[:len(trg_data)]\n",
        "\n",
        "        #### Train Model\n",
        "        m1 = np.concatenate((x_temp,trg_samples))\n",
        "        m2 = np.concatenate((y_temp,trg_pseudo_labels)).astype(np.int32)\n",
        "        m3 = np.concatenate((w_temp,weights_trg)).astype(np.float32)\n",
        "        \n",
        "                                    \n",
        "        ### Balancing the positive and negative samples\n",
        "        pos_inds = m2==1\n",
        "        x_train_pos = m1[pos_inds]\n",
        "        y_train_pos = m2[pos_inds]\n",
        "        w_train_pos = m3[pos_inds]\n",
        "        x_train_neg = m1[~pos_inds]\n",
        "        y_train_neg = m2[~pos_inds]\n",
        "        w_train_neg = m3[~pos_inds]\n",
        "        p = np.random.permutation(len(x_train_neg))\n",
        "        x_train_neg = x_train_neg[p]\n",
        "        y_train_neg = y_train_neg[p]\n",
        "        w_train_neg = w_train_neg[p]\n",
        "        pos_len = len(x_train_pos)\n",
        "\n",
        "        DA_dhandler = DataHandler(np.concatenate((x_train_pos,x_train_neg[:pos_len]))\n",
        "                                ,np.concatenate((y_train_pos,y_train_neg[:pos_len]))\n",
        "                                ,np.concatenate((w_train_pos,w_train_neg[:pos_len])),batch_size=256,shuffle=True)            \n",
        "\n",
        "        ep = 1\n",
        "        train_model_with_weights(ep,DA_dhandler,tsolver, train_loss, train_step_DA)\n",
        "\n",
        "        if nnn%8==0:\n",
        "            current_f1 = calc_f1_score(trg_data,trg_gts, tsolver.net)\n",
        "            print('Current F1 score on the trg domain:',current_f1)"
      ],
      "metadata": {
        "id": "ccdkwY3uBPaq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_model_with_PPPL(net, W):\n",
        "    train_step_DA = tf.function(train_step_DA_eager)\n",
        "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "    base_lr = 0.0001\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=base_lr)\n",
        "    grads = []\n",
        "    for v in net.trainable_variables:\n",
        "        grads.append(np.zeros(v.shape,dtype=np.float32))\n",
        "    optimizer.apply_gradients(zip(grads,net.trainable_variables))\n",
        "    tsolver = Solver(optimizer,net,base_lr)\n",
        "\n",
        "    trg_gts = y_trg\n",
        "    trg_data = x_trg\n",
        "    src_gts = y_src\n",
        "    src_data = x_src\n",
        "    t_labels = np.array(trg_gts)\n",
        "    s_labels = np.array(src_gts)\n",
        "\n",
        "    n_classes = 2\n",
        "    trg_cp = np.zeros(n_classes)\n",
        "    for i in range(n_classes):\n",
        "        trg_cp[i] = np.sum(s_labels==i)/len(s_labels)\n",
        "\n",
        "    DA(tsolver,trg_data,trg_gts,src_data,src_gts,trg_cp, train_loss, train_step_DA, W=W)\n"
      ],
      "metadata": {
        "id": "omUpkSUwzVIo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_one_model_with_PPPL(net1, W=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37e93n_p0Xfj",
        "outputId": "19ae8562-0bca-4757-940a-697611781986"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 1 Elapsed Time(m): 0.00\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0152  \n",
            "Current F1 score on the trg domain: 0.08324604607281615\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 2 Elapsed Time(m): 0.14\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0105  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 3 Elapsed Time(m): 0.23\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0105  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 4 Elapsed Time(m): 0.31\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0103  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 5 Elapsed Time(m): 0.39\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0104  \n",
            "Current F1 score on the trg domain: 0.11285892634207242\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 6 Elapsed Time(m): 0.53\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0093  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 7 Elapsed Time(m): 0.61\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0096  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 8 Elapsed Time(m): 0.69\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0097  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 9 Elapsed Time(m): 0.77\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0093  \n",
            "Current F1 score on the trg domain: 0.17630004667015514\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 10 Elapsed Time(m): 0.91\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0096  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 11 Elapsed Time(m): 1.00\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0091  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 12 Elapsed Time(m): 1.08\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0093  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 13 Elapsed Time(m): 1.16\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0083  \n",
            "Current F1 score on the trg domain: 0.19800324595485172\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 14 Elapsed Time(m): 1.30\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0086  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 15 Elapsed Time(m): 1.38\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0081  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 16 Elapsed Time(m): 1.47\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0077  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 17 Elapsed Time(m): 1.55\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0077  \n",
            "Current F1 score on the trg domain: 0.23725565879076949\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 18 Elapsed Time(m): 1.70\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0080  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 19 Elapsed Time(m): 1.78\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0086  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 20 Elapsed Time(m): 1.87\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0083  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 21 Elapsed Time(m): 1.96\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0075  \n",
            "Current F1 score on the trg domain: 0.2918526303186713\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 22 Elapsed Time(m): 2.10\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0083  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 23 Elapsed Time(m): 2.19\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0077  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 24 Elapsed Time(m): 2.28\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0074  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 25 Elapsed Time(m): 2.37\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0072  \n",
            "Current F1 score on the trg domain: 0.3686402065509037\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 26 Elapsed Time(m): 2.51\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0074  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 27 Elapsed Time(m): 2.60\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0081  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 28 Elapsed Time(m): 2.70\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0077  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 29 Elapsed Time(m): 2.79\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0071  \n",
            "Current F1 score on the trg domain: 0.48725179453714934\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 30 Elapsed Time(m): 2.94\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0075  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 31 Elapsed Time(m): 3.03\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0096  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 32 Elapsed Time(m): 3.13\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0084  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 33 Elapsed Time(m): 3.23\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0074  \n",
            "Current F1 score on the trg domain: 0.7135884096940387\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 34 Elapsed Time(m): 3.38\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0071  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 35 Elapsed Time(m): 3.48\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0071  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 36 Elapsed Time(m): 3.58\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0067  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 37 Elapsed Time(m): 3.68\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0069  \n",
            "Current F1 score on the trg domain: 0.7842852289456796\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 38 Elapsed Time(m): 3.84\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0064  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 39 Elapsed Time(m): 3.94\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0061  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 40 Elapsed Time(m): 4.05\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0060  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 41 Elapsed Time(m): 4.15\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0057  \n",
            "Current F1 score on the trg domain: 0.7766955025569947\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 42 Elapsed Time(m): 4.30\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0064  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 43 Elapsed Time(m): 4.40\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0062  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 44 Elapsed Time(m): 4.51\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0058  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 Elapsed Time(m): 4.61\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0063  \n",
            "Current F1 score on the trg domain: 0.7117874958851383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DA_f1_score = calc_f1_score(x_trg,y_trg, net1)\n",
        "print('F1 score on the trg domain (Model 1):',DA_f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVDub1rd0n0n",
        "outputId": "479140d3-e45c-409f-ac18-31f178b67f5b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score on the trg domain (Model 1): 0.7117874958851383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-15T22:52:17.283151Z",
          "start_time": "2021-06-15T22:52:17.259960Z"
        },
        "id": "Qh-U2Dlg0-r-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f466b53-c1ef-4b61-9739-e996ba196064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 1 Elapsed Time(m): 0.00\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0137  \n",
            "Current F1 score on the trg domain: 0.0772909377121584\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 2 Elapsed Time(m): 0.14\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0105  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 3 Elapsed Time(m): 0.22\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0106  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 4 Elapsed Time(m): 0.30\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0105  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 5 Elapsed Time(m): 0.38\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0104  \n",
            "Current F1 score on the trg domain: 0.11303501803205536\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 6 Elapsed Time(m): 0.51\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0102  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 7 Elapsed Time(m): 0.59\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0103  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 8 Elapsed Time(m): 0.67\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0096  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 9 Elapsed Time(m): 0.75\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0090  \n",
            "Current F1 score on the trg domain: 0.18075054565936774\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 10 Elapsed Time(m): 0.89\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0092  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 11 Elapsed Time(m): 0.97\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0084  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 12 Elapsed Time(m): 1.05\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0090  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 13 Elapsed Time(m): 1.13\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0090  \n",
            "Current F1 score on the trg domain: 0.22335914390716466\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 14 Elapsed Time(m): 1.27\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0092  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 15 Elapsed Time(m): 1.36\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0084  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 16 Elapsed Time(m): 1.44\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0092  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 17 Elapsed Time(m): 1.53\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0086  \n",
            "Current F1 score on the trg domain: 0.3131151502485093\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 18 Elapsed Time(m): 1.67\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0092  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 19 Elapsed Time(m): 1.76\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0089  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 20 Elapsed Time(m): 1.85\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0087  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 21 Elapsed Time(m): 1.94\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0089  \n",
            "Current F1 score on the trg domain: 0.5528162200118322\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 22 Elapsed Time(m): 2.08\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0100  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 23 Elapsed Time(m): 2.17\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0101  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 24 Elapsed Time(m): 2.27\n",
            "epoch: 1/1 ETA: 0:00 loss: 0.0094  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 25 Elapsed Time(m): 2.37\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0090  \n",
            "Current F1 score on the trg domain: 0.8669050109180337\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 26 Elapsed Time(m): 2.52\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0090  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 27 Elapsed Time(m): 2.63\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0079  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 28 Elapsed Time(m): 2.74\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0079  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 29 Elapsed Time(m): 2.84\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0075  \n",
            "Current F1 score on the trg domain: 0.9464747895029977\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 30 Elapsed Time(m): 3.01\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0071  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 31 Elapsed Time(m): 3.12\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0071  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 32 Elapsed Time(m): 3.23\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0065  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 33 Elapsed Time(m): 3.35\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0063  \n",
            "Current F1 score on the trg domain: 0.9617156950236083\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 34 Elapsed Time(m): 3.52\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0065  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 35 Elapsed Time(m): 3.63\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0059  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 36 Elapsed Time(m): 3.75\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0059  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 37 Elapsed Time(m): 3.87\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0055  \n",
            "Current F1 score on the trg domain: 0.9664230604808339\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 38 Elapsed Time(m): 4.04\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0056  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 39 Elapsed Time(m): 4.17\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0052  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 40 Elapsed Time(m): 4.29\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0054  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 41 Elapsed Time(m): 4.41\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0052  \n",
            "Current F1 score on the trg domain: 0.9690772011528879\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 42 Elapsed Time(m): 4.60\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0053  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 43 Elapsed Time(m): 4.72\n",
            "epoch: 1/1 ETA: 0:02 loss: 0.0052  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 44 Elapsed Time(m): 4.85\n",
            "epoch: 1/1 ETA: 0:01 loss: 0.0056  \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ i: 45 Elapsed Time(m): 4.98\n",
            "epoch: 1/1 ETA: 0:02 loss: 0.0056  \n",
            "Current F1 score on the trg domain: 0.9713370644754296\n"
          ]
        }
      ],
      "source": [
        "train_one_model_with_PPPL(net2, W=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DA_f1_score = calc_f1_score(x_trg,y_trg, net2)\n",
        "print('F1 score on the trg domain (Model 2):',DA_f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUmPmZ-02U6g",
        "outputId": "a321f08e-3dfa-482d-876e-8a0214f2ec8e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score on the trg domain (Model 2): 0.9713370644754296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble of models"
      ],
      "metadata": {
        "id": "Dr0kxcFW3lVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trg_pseudo_labels1, trg_scores_np1  = test(x_trg,np.zeros_like(y_trg),net1,ret=True)\n",
        "\n",
        "trg_pseudo_labels2, trg_scores_np2  = test(x_trg,np.zeros_like(y_trg),net2,ret=True)"
      ],
      "metadata": {
        "id": "t99gu1eD3sTj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_scores_np = (trg_scores_np1 + trg_scores_np2)/2\n",
        "ensemble_preds_np = np.argmax(ensemble_scores_np, axis=1)\n",
        "ensemble_f1_score = metrics.f1_score(y_true=y_trg,y_pred=ensemble_preds_np)\n",
        "print('F1 score on the trg domain (Ensemble of Models):',ensemble_f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPO-etH04H0y",
        "outputId": "0d47e9bf-2615-4b6a-ec82-49a2423267c4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score on the trg domain (Ensemble of Models): 0.9007498095172127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection"
      ],
      "metadata": {
        "id": "GeYLivs35DJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_noise = np.random.uniform(size=x_src.shape)"
      ],
      "metadata": {
        "id": "Cpo_lqid5EhZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GeneralizationScores = [0,0]\n",
        "for i in range(0,20):\n",
        "    scaler = 0.01*(i+1)\n",
        "    GeneralizationScores[0]+=calc_f1_score(rand_noise*scaler+x_src,y_src,net1)\n",
        "    GeneralizationScores[1]+=calc_f1_score(rand_noise*scaler+x_src,y_src,net2)\n",
        "    print(GeneralizationScores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO8qszxQ6kcX",
        "outputId": "00b180f8-fee1-4e9a-ef0a-16d7950f2e40"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9480213089802131, 0.9452614691164674]\n",
            "[1.8758722305925282, 1.8337458044255275]\n",
            "[2.2763803284013564, 2.2923437526424304]\n",
            "[2.3694921845427768, 2.520068620367298]\n",
            "[2.3922950348990715, 2.649071979829784]\n",
            "[2.399004836001396, 2.72736488741345]\n",
            "[2.4023667186556823, 2.7796972602816066]\n",
            "[2.4039690259782267, 2.815680918358288]\n",
            "[2.404610308543357, 2.8387767025867148]\n",
            "[2.405090923730797, 2.8533937982333626]\n",
            "[2.4052506681397428, 2.864207187753916]\n",
            "[2.4052506681397428, 2.872150630441977]\n",
            "[2.4052506681397428, 2.8784817478842055]\n",
            "[2.4052506681397428, 2.8827266971806447]\n",
            "[2.4052506681397428, 2.8863014562729665]\n",
            "[2.4052506681397428, 2.888578496121164]\n",
            "[2.4052506681397428, 2.8907342880153863]\n",
            "[2.4052506681397428, 2.89245034636137]\n",
            "[2.4052506681397428, 2.8937387797435075]\n",
            "[2.4052506681397428, 2.895068907128784]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [net1, net2]\n",
        "best_model = models[np.argmax(GeneralizationScores)]\n",
        "\n",
        "best_model_f1_score = calc_f1_score(x_trg,y_trg, best_model)\n",
        "print('F1 score on the trg domain (Model Selection):',best_model_f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gueEEzUE7Ko0",
        "outputId": "94eac4b2-986e-44f7-8ba9-29269f959687"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score on the trg domain (Model Selection): 0.9713370644754296\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "412.186px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}